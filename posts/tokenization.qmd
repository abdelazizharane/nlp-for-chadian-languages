---
title: "Tokenization des langues tchadiennes"
author: "Abdel-aziz Harane"
date: "2024-02-20"
categories: [Tokenization, Preprocessing]
---

Dans ce guide, je partage avec vous les approches qu'on a adopt√© dans la cr√©atio d'un _tokenizer_ pour la langue `arabe tchadien (shu)` qui est appliquable √† nos autres langues locales. Nous discuterons de la litt√©rature, des algorithmes existants et je vous expliquerais comment j'ai impl√©menter le n√¥tre.

::: {.callout-note}
Il est n√©cessaire de cr√©er un nouveau tokenizer pour pouvoir entrainer √† partir de z√©ro ou affiner un mod√®le pr√© entrain√©. 
:::

Dans le cadre de ce projet, nous avons appliqu√© **trois principaux algorithmes** de tokenization.
Chacun pr√©sente des avantages et des inconv√©nients, nous permettant d'explorer et de mieux comprendre le fonctionnement de la tokenization, notamment pour la langue arabe tchadienne (shu).

<!-- more -->

Nous allons d'abord expliquer ce qu'est la tokenization, pourquoi elle est importante et comment elle fonctionne, avant de d√©couvrir ensemble les trois m√©thodes que nous avons utilis√©es.

??? info "Qu'est-ce qu'un tokenizer ?"
    Pour apprendre √† un ordinateur √† lire et comprendre une phrase, nous devons √† priori num√©riser ces mots (vectorisation) pour qu'il puisse comprendre. Pour la machine, il est impossible de comprendre les mots brutes sans les faire passer par une moulette. C'est-√†-dire une machine ne comprend que 1 et 0 et pour elle, une phrase est juste une suite de lettres coll√©es les unes aux autres. Elle a donc besoin d'un outil pour d√©couper la phrase en petits morceaux compr√©hensibles et num√©riques. Ce d√©coupage s'appelle la **tokenization** et **l'encodage** lorsque cette phrase est vectoris√©e comme `[129, 103, 192]`.

Par exemple, la phrase :

```{text} title="une phrase en shu"
**"Zahra indaha khalag asfar"**
Peut √™tre transform√©e en :

- `"Zahra"`
- `"indaha"`
- `"khalag"`
- `"asfar"`
```

Ces morceaux sont appel√©s des **tokens**, et l'ordinateur peut maintenant travailler avec eux plus facilement.

!!! note "Les langues tchadiennes et la tokenization"

      Les langues tchadiennes, comme l'arabe tchadien et le ngambaye, pr√©sentent des d√©fis uniques en tokenization. L'arabe tchadien, par exemple, utilise une √©criture attach√©e et des mots qui peuvent √™tre tr√®s longs lorsqu'ils contiennent des pr√©fixes et suffixes. Il est donc essentiel de tester plusieurs algorithmes et si besoin d'en cr√©er un autre (ce que nous allons faire).

### **Les 3 algorithmes les plus utilis√©s üëáüèø**

::: panel-tabset
## BPE (Byte Pair Encoding)

??? info "C'est quoi BPE ?"
    Lors qu'on veut apprendre √† √©crire un texte en utilisant le moins de place possible ou plut√¥t que de stocker chaque mot individuellement, nous pouvons donc rep√©rer les lettres ou les groupes de lettres les plus fr√©quents et les remplacer par un symbole plus court.

```{text} title="exemple en shu"
    - Phrase originale : **"Zahra indaha khalag asfar"**
    - D√©coupage en tokens : **["Za", "hra", "inda", "ha", "kha", "lag", "as", "far"]**
    - Apr√®s BPE : **["#A", "inda", "ha", "#B"]** (o√π #A et #B sont des unit√©s apprises)
```

## Sentencepiece

??? info "C'est quoi Sentencepiece ?"
Imagineons que nous avons une phrase et voulons la d√©couper, mais nous ne voulons pas seulement couper aux espaces (car certaines langues n'ont pas d'espaces clairs entre les mots comme le Chinois). Sentencepiece apprend √† d√©couper la phrase en morceaux de mani√®re plus flexible.
```{text} title="exemple en shu"
    - Phrase originale : **"Al-naadum da gaa'id fil-beet"**
    - Tokenization avec SentencePiece : **["Al-", "naadum", "da", "gaa'id", "fil-", "beet"]**
    - SentencePiece peut aussi d√©couper : **["Al", "na", "adum", "da", "gaa'", "id", "fil", "beet"]** pour plus de flexibilit√©.
```

## Wordpiece

??? info "C'est quoi WordPiece ?"

WordPiece est un algorithme qui coupe une phrase en sous-unit√©s, en favorisant les segments les plus fr√©quemment rencontr√©s dans les donn√©es d'entra√Ænement. Cette approche est utilis√©e dans des mod√®les comme BERT.
```{r} title="exemple en shu"
    - Phrase originale : **"Zahra indaha khalag asfar"**
    - Tokenization avec WordPiece : **["Zah", "##ra", "inda", "##ha", "khal", "##ag", "as", "##far"]**
```

Cela permet de garder des unit√©s fr√©quentes tout en fragmentant les mots moins courants.
:::



Ces trois m√©thodes nous ont permit de mieux adapter la tokenization en cr√©ant notre propre `tokenizer` sur le vocabulaire de l'arabe tchadienne.
Cette approche pourrais √™tre √©tendue √† d'autres langues locales telles que : Sara, Kanembou, Moundang, Zaghawa, ... C'est une premi√®re exp√©rimentation et nous l'adapterons √† nos autres langues locales.


Esperant qu'il vous a aid√©, N'h√©sitez pas de le partager avec vos pairs.
