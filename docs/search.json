[
  {
    "objectID": "posts/tokenization.html",
    "href": "posts/tokenization.html",
    "title": "Tokenization des langues tchadiennes",
    "section": "",
    "text": "Dans ce guide, je partage avec vous les approches qu’on a adopté dans la créatio d’un tokenizer pour la langue arabe tchadien (shu) qui est appliquable à nos autres langues locales. Nous discuterons de la littérature, des algorithmes existants et je vous expliquerais comment j’ai implémenter le nôtre.\nDans le cadre de ce projet, nous avons appliqué trois principaux algorithmes de tokenization. Chacun présente des avantages et des inconvénients, nous permettant d’explorer et de mieux comprendre le fonctionnement de la tokenization, notamment pour la langue arabe tchadienne (shu).\nNous allons d’abord expliquer ce qu’est la tokenization, pourquoi elle est importante et comment elle fonctionne, avant de découvrir ensemble les trois méthodes que nous avons utilisées.\n??? info “Qu’est-ce qu’un tokenizer ?” Pour apprendre à un ordinateur à lire et comprendre une phrase, nous devons à priori numériser ces mots (vectorisation) pour qu’il puisse comprendre. Pour la machine, il est impossible de comprendre les mots brutes sans les faire passer par une moulette. C’est-à-dire une machine ne comprend que 1 et 0 et pour elle, une phrase est juste une suite de lettres collées les unes aux autres. Elle a donc besoin d’un outil pour découper la phrase en petits morceaux compréhensibles et numériques. Ce découpage s’appelle la tokenization et l’encodage lorsque cette phrase est vectorisée comme [129, 103, 192].\nPar exemple, la phrase :\n```vvuvpl title=“une phrase en shu” “Zahra indaha khalag asfar” Peut être transformée en :"
  },
  {
    "objectID": "posts/tokenization.html#sentencepiece",
    "href": "posts/tokenization.html#sentencepiece",
    "title": "Tokenization des langues tchadiennes",
    "section": "Sentencepiece",
    "text": "Sentencepiece\n??? info “C’est quoi Sentencepiece ?” Imagineons que nous avons une phrase et voulons la découper, mais nous ne voulons pas seulement couper aux espaces (car certaines langues n’ont pas d’espaces clairs entre les mots comme le Chinois). Sentencepiece apprend à découper la phrase en morceaux de manière plus flexible. vvuvpl title=\"exemple en shu\"     - Phrase originale : **\"Al-naadum da gaa'id fil-beet\"**     - Tokenization avec SentencePiece : **[\"Al-\", \"naadum\", \"da\", \"gaa'id\", \"fil-\", \"beet\"]**     - SentencePiece peut aussi découper : **[\"Al\", \"na\", \"adum\", \"da\", \"gaa'\", \"id\", \"fil\", \"beet\"]** pour plus de flexibilité."
  },
  {
    "objectID": "posts/tokenization.html#wordpiece",
    "href": "posts/tokenization.html#wordpiece",
    "title": "Tokenization des langues tchadiennes",
    "section": "Wordpiece",
    "text": "Wordpiece\n??? info “C’est quoi WordPiece ?”\nWordPiece est un algorithme qui coupe une phrase en sous-unités, en favorisant les segments les plus fréquemment rencontrés dans les données d’entraînement. Cette approche est utilisée dans des modèles comme BERT. cux title=\"exemple en shu\"     - Phrase originale : **\"Zahra indaha khalag asfar\"**     - Tokenization avec WordPiece : **[\"Zah\", \"##ra\", \"inda\", \"##ha\", \"khal\", \"##ag\", \"as\", \"##far\"]**\nCela permet de garder des unités fréquentes tout en fragmentant les mots moins courants. :::\nCes trois méthodes nous ont permit de mieux adapter la tokenization en créant notre propre tokenizer sur le vocabulaire de l’arabe tchadienne. Cette approche pourrais être étendue à d’autres langues locales telles que : Sara, Kanembou, Moundang, Zaghawa, … C’est une première expérimentation et nous l’adapterons à nos autres langues locales.\nEsperant qu’il vous a aidé, N’hésitez pas de le partager avec vos pairs."
  },
  {
    "objectID": "modelisation_language.html",
    "href": "modelisation_language.html",
    "title": "Modelisation linguistique",
    "section": "",
    "text": "Les langues tchadiennes sont nombreuses et variées, mais elles restent largement sous-représentées dans le domaine du traitement automatique du langage (NLP). Pour combler ce vide, nous devons développer des modèles de langage adaptés à ces langues, capables de comprendre et de générer du texte de manière fluide et pertinente.\n::: ??? info “Pourquoi est-ce important ?”\nImaginez un étudiant tchadien souhaitant poser une question en Ngambaye à un moteur de recherche, ou un commerçant voulant rédiger une annonce en kanembou. Aujourd’hui, peu de technologies permettent ces interactions. La modélisation du langage ouvre la porte à un avenir où les langues tchadiennes seront pleinement intégrées dans le numérique. :::\n\nLes défis de la modélisation du langage\n\n1. Manque de corpus textuels\nLes modèles de langage nécessitent de grandes quantités de textes pour apprendre. Or, aucun autre corpus existe pour les langues tchadiennes à part le premier corpus qu’on a créé.\nSolutions envisagées :\n\nCollecte et numérisation de documents existants\nWeb scraping et application de l’OCR des données existantes sur l’Internet\nCréation de bases de données textuelles à partir de transcriptions de conversations\nCrowdsourcing pour enrichir les corpus avec la contribution des locuteurs natifs\n\n\n\n2. Orthographe et variabilité linguistique\nCertaines langues tchadiennes ont plusieurs variantes dialectales, rendant la plus standardisation difficile.\nApproche :\n\nDéveloppement de modèles capables de s’adapter aux variations dialectales.\nUtilisation de techniques de normalisation textuelle pour réduire la variabilité dans les corpus d’entraînement.\n\n\n\n3. Intégration du multilinguisme\nLes Tchadiens parlent souvent plusieurs langues (ex. arabe tchadien, français, langues locales). D’où il est important dans notre projet d’inclure cet aspect dans la modélisation.\nApproche :\n\nCréation de modèles de traduction automatique entre les langues tchadiennes et les langues internationales.\nEntraînement de modèles multilingues capables de passer d’une langue à l’autre en fonction du contexte.\n\n\n\n\nTechniques de modélisation utilisées\n\n1. Modèles basés sur les N-grammes\nLes modèles n-grammes sont simples mais efficaces pour les langues peu dotées en ressources. Ils analysent des séquences de mots pour prédire le suivant.\nExemple : Si nous avons la phrase “Na ala…” en Sara, le modèle peut prédire que “ngo” est un mot probable suivant.\n\n\n2. Modèles neuronaux avec embeddings\nLes modèles de word embeddings permettent de représenter chaque mot sous forme de vecteur mathématique, facilitant la compréhension des relations entre mots.\nExemple : Un modèle entraîné pourra comprendre que “beera” (maison en arabe tchadien) est proche de “daar” (maison en arabe classique) en termes de sens.\n\n\n3. Utilisation de transformers (ex. BERT, GPT)\nLes modèles de type Transformers, comme BERT et GPT, offrent des très bonnes performances pour la modélisation du langage.\nExemple d’application : Un chatbot basé sur BERT peut comprendre et répondre en plusieurs langues tchadiennes tout en tenant compte du contexte de la conversation.\n\n\n\nApplications et perspectives\nL’amélioration des modèles NLP pour les langues tchadiennes ouvrira de nombreuses possibilités :\n\nChatbots multilingues pour l’éducation, les services publics et d’autres cas d’usage\nSystèmes de reconnaissance vocale adaptés aux accents locaux\nTraduction automatique plus précise entre les langues locales et internationales\nSynthèse vocale (TTS) pour rendre les contenus accessibles aux personnes non lettrées."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Articles 🗃️",
    "section": "",
    "text": "Bienvenue dans ce BLOG de la documentation détaillée de toutes les étapes de ce projet NLP portant sur les langues tchadiennes. Vous découvrirez nos articles soigneusement rédigés ✍🏿 pour vous offrir une expérience de lecture enrichissante."
  },
  {
    "objectID": "blog.html#bonne-lecture",
    "href": "blog.html#bonne-lecture",
    "title": "Articles 🗃️",
    "section": "Bonne lecture !🤗",
    "text": "Bonne lecture !🤗"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "A propos",
    "section": "",
    "text": "Le Tchad est un pays riche en diversité linguistique et culturelle, avec plus de 123 langues autochtones répertoriées selon le site Ethnologue. Ce projet vise à exploiter les techniques de traitement du langage naturel (NLP) pour préserver et promouvoir nos langues uniques en collaboration avec les linguistes tchadiens et ceux de l’étranger.\n\n\nL’objectif principal de ce projet est de développer des outils et des ressources NLP pour les langues tchadiennes. Cela inclut la création de corpus linguistiques, le développement de modèles de reconnaissance vocale et de transcription (ASR et TTS) et la traduction automatique. En collaborant avec des linguistes et des experts en technologie, nous espérons faciliter la recherche et l’enseignement de ces langues.\n\nLinguistique computationnelleNLP 🎙️LLM (large language model)\n\n\nDécouvrez le pouvoir de la linguistique computationnelle appliquée aux langues tchadiennes. Cliquez sur l’onglet Blog pour en savoir plus !\nLa linguistique computationnelle joue un rôle crucial dans la préservation des langues en danger (en voie de disparution). Nous pouvons analyser et documenter les langues tchadiennes de manière plus efficace en appliquant les techniques avancées de NLP (lemmatization, tokenization, NER, etc.). Cela permet non seulement de sauvegarder ces langues pour les générations futures, mais aussi de les rendre accessibles à un public plus large.\n\n\nExplorez les techniques de traitement du langage naturel (NLP) pour les langues tchadiennes. Cliquez sur l’onglet Blog pour plus de détails.\n\n\nJe nourris une passion constante pour la lecture (les livres sont mes amis fidèles). Toujours avide de nouvelles connaissances, je vous invite à découvrir plus sur le projet en cliquant sur l’onglet Blog.\n\n\n\n\n\n\nToute la documentation des données est disponible sur le repository Corpus chadian languages. Vous y trouverez des corpus annotés, des modèles pré-entraînés et des guides pour vous aider à démarrer avec les outils NLP pour les langues tchadiennes.\nNous vous invitons à explorer ces ressources et à contribuer à ce projet d’intérêt général. La documentation, la préservation et la promotion des langues tchadiennes est notre priorité absolue à travers ce projet."
  },
  {
    "objectID": "about.html#projet-de-traitement-automatique-du-langage-naturel-taln---nlp-pour-les-langues-tchadiennes",
    "href": "about.html#projet-de-traitement-automatique-du-langage-naturel-taln---nlp-pour-les-langues-tchadiennes",
    "title": "A propos",
    "section": "",
    "text": "Le Tchad est un pays riche en diversité linguistique et culturelle, avec plus de 123 langues autochtones répertoriées selon le site Ethnologue. Ce projet vise à exploiter les techniques de traitement du langage naturel (NLP) pour préserver et promouvoir nos langues uniques en collaboration avec les linguistes tchadiens et ceux de l’étranger.\n\n\nL’objectif principal de ce projet est de développer des outils et des ressources NLP pour les langues tchadiennes. Cela inclut la création de corpus linguistiques, le développement de modèles de reconnaissance vocale et de transcription (ASR et TTS) et la traduction automatique. En collaborant avec des linguistes et des experts en technologie, nous espérons faciliter la recherche et l’enseignement de ces langues.\n\nLinguistique computationnelleNLP 🎙️LLM (large language model)\n\n\nDécouvrez le pouvoir de la linguistique computationnelle appliquée aux langues tchadiennes. Cliquez sur l’onglet Blog pour en savoir plus !\nLa linguistique computationnelle joue un rôle crucial dans la préservation des langues en danger (en voie de disparution). Nous pouvons analyser et documenter les langues tchadiennes de manière plus efficace en appliquant les techniques avancées de NLP (lemmatization, tokenization, NER, etc.). Cela permet non seulement de sauvegarder ces langues pour les générations futures, mais aussi de les rendre accessibles à un public plus large.\n\n\nExplorez les techniques de traitement du langage naturel (NLP) pour les langues tchadiennes. Cliquez sur l’onglet Blog pour plus de détails.\n\n\nJe nourris une passion constante pour la lecture (les livres sont mes amis fidèles). Toujours avide de nouvelles connaissances, je vous invite à découvrir plus sur le projet en cliquant sur l’onglet Blog.\n\n\n\n\n\n\nToute la documentation des données est disponible sur le repository Corpus chadian languages. Vous y trouverez des corpus annotés, des modèles pré-entraînés et des guides pour vous aider à démarrer avec les outils NLP pour les langues tchadiennes.\nNous vous invitons à explorer ces ressources et à contribuer à ce projet d’intérêt général. La documentation, la préservation et la promotion des langues tchadiennes est notre priorité absolue à travers ce projet."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "🏠 Acceuil",
    "section": "",
    "text": "Bienvenue - Welcome - مرحبا - dans la documentation NLP des langue thcadiennes\nToute la documentation des données est disponible sur le repository Corpus chadian languages."
  },
  {
    "objectID": "index.html#projet-nlp-pour-les-langues-tchadiennes",
    "href": "index.html#projet-nlp-pour-les-langues-tchadiennes",
    "title": "🏠 Acceuil",
    "section": "Projet NLP pour les Langues Tchadiennes",
    "text": "Projet NLP pour les Langues Tchadiennes\nVous allez apprendre à travers ces slides sur les langues du Tchad\nLe Tchad est un pays avec une large diversité linguistique et culturelle et compte plus de 123 langues autochtones selon le site Ethnologue.\nNous avons entre autre :\n\n\nAdamawa Fulfulde [fub], Amdang [amj], Assangori [sjg], Bagirmi [bmi], Bagirmi Fulfulde [fui], Barein [bva], Bedjond [bjv], Berakou [bxv], Besme [bes], Bidiyo [bid], Birgit [btf], Bolgo [bvo], Bon Gula [glc], Boor [bvf], Bua [bub], Buduma [bdm], Buso [bso], Chadian Arabic [shu], Chadian Sign Language [cds], Dangaléat [daa], Dar Daju Daju [djc], Dar Sila Daju [dau],\n\nDay [dai], Dazaga [dzg], Disa [dsi], Fania [fni], Fongoro [fgr], Fur [fvr], Gabri [gab], Gadang [gdk], Gidar [gid], Gor [gqr], Goundo [goy], Gula [glu], Gula Iro [glj], Gulay [gvl], Herdé [hed], Horo [hor], Jaya [jyy], Jonkor Bourmataguil [jeu],Kaba [ksp], Kabalai [kvf], Kajakse [ckq], Kanembu [kbl], Karang [kzr], Karanga [kth], Kendeje [klf], Kenga [kyq], Kera [ker], Kibet [kie], Kim [kia], Kimré [kqp], Koke [kou], Kujarge [vkj], Kulfa [kxj], Kuo [xuo], Kwang [kvi], Laal [gdm], Lagwan [kot], Laka [lap], Lele [lln], Luto [ndy], Maba [mde], Mabire [muj], Majera [xmj], Malgbe [mxf], Mambai [mcs], Mango [mge], Mararit [mgb], Marba [mpg], Marfa [mvu], Masalit [mls], Masana [mcn], Maslam [msv], Masmaje [mes], Massalat [mdg], Mawa [mcw], Mbara [mpk], Mbay [myb], Mesme [zim], Migaama [mmy], Miltu [mlj], Mogum [mou], Morom [bdo], Mpade [mpi], Mser [kqx], Mubi [mub], Mukulu [moz], Mulgi [mvh], Mundang [mua], Musey [mse], Musgu [mug], Muskum [mje], Naba [mne], Nancere [nnc], Ndam [ndm], Ngam [nmc], Ngambay [sba], Ngete [nnn], Niellim [nie], Noy [noy], Nzakambay [nzy], Pana [pnz], Pévé [lme], Runga [rou], Saba [saa], Sar [mwm], Sara Kaba Démé [kwg], Sara Kaba Naa [kwv], Sarua [swy], Sinyar [sys], Sokoro [sok], Soumraye [sor], Surbakhal [sbj], Tama [tma], Tamki [tax], Tedaga [tuq], Tobanga [tng], Toram [trj], Tumak [tmc], Tunia [tug], Tupuri [tui], Ubi [ubi], Yerwa Kanuri [knc], Zaghawa [zag], Zan Gula [zna]\n\n\n\n\n\n\nLangues tchadiennes\n\n\n\nAdamawa Fulfulde [fub], Amdang [amj], Assangori [sjg], Bagirmi [bmi], Bagirmi Fulfulde [fui], Barein [bva], Bedjond [bjv], Berakou [bxv], Besme [bes], Bidiyo [bid], Birgit [btf], Bolgo [bvo], Bon Gula [glc], Boor [bvf], Bua [bub], Buduma [bdm], Buso [bso], Chadian Arabic [shu], Chadian Sign Language [cds], Dangaléat [daa], Dar Daju Daju [djc], Dar Sila Daju [dau], Day [dai], Dazaga [dzg], Disa [dsi], Fania [fni], Fongoro [fgr], Fur [fvr], Gabri [gab], Gadang [gdk], Gidar [gid], Gor [gqr], Goundo [goy], Gula [glu], Gula Iro [glj], Gulay [gvl], Herdé [hed], Horo [hor], Jaya [jyy], Jonkor Bourmataguil [jeu], Kaba [ksp], Kabalai [kvf], Kajakse [ckq], Kanembu [kbl], Karang [kzr], Karanga [kth], Kendeje [klf], Kenga [kyq], Kera [ker], Kibet [kie], Kim [kia], Kimré [kqp], Koke [kou], Kujarge [vkj], Kulfa [kxj], Kuo [xuo], Kwang [kvi], Laal [gdm], Lagwan [kot], Laka [lap], Lele [lln], Luto [ndy], Maba [mde], Mabire [muj], Majera [xmj], Malgbe [mxf], Mambai [mcs], Mango [mge], Mararit [mgb], Marba [mpg], Marfa [mvu], Masalit [mls], Masana [mcn], Maslam [msv], Masmaje [mes], Massalat [mdg], Mawa [mcw], Mbara [mpk], Mbay [myb], Mesme [zim], Migaama [mmy], Miltu [mlj], Mogum [mou], Morom [bdo], Mpade [mpi], Mser [kqx], Mubi [mub], Mukulu [moz], Mulgi [mvh], Mundang [mua], Musey [mse], Musgu [mug], Muskum [mje], Naba [mne], Nancere [nnc], Ndam [ndm], Ngam [nmc], Ngambay [sba], Ngete [nnn], Niellim [nie], Noy [noy], Nzakambay [nzy], Pana [pnz], Pévé [lme], Runga [rou], Saba [saa], Sar [mwm], Sara Kaba Démé [kwg], Sara Kaba Naa [kwv], Sarua [swy], Sinyar [sys], Sokoro [sok], Soumraye [sor], Surbakhal [sbj], Tama [tma], Tamki [tax], Tedaga [tuq], Tobanga [tng], Toram [trj], Tumak [tmc], Tunia [tug], Tupuri [tui], Ubi [ubi], Yerwa Kanuri [knc], Zaghawa [zag], Zan Gula [zna]\n\n\nToutes ces langues tchadiennes sont absentes du monde numérique. Imaginez que l’un de vous veut parler uniquement Zaghawa ou Toupouri, essayant d’interagir avec un chatbot en ligne. Aujourd’hui, vous n’avez aucune option. Nous voulons changer cela.\ndans le développement des technologies de traitement du langage naturel (TALN ou NLP - Natural Language Processing).\nNotre projet ambitionne de développer des modèles de traitement du langage naturel (TALN ou NLP - Natural Language Processing)capables de comprendre et de répondre en langues tchadiennes.\nEn commençant par l’arabe tchadien, nous construirons progressivement des modèles pour d’autres langues locales. Mais nous ne nous arrêtons pas là : à long terme, nous souhaitons aller bien au-delà du texte.\n??? info “Pourquoi ce projet est-il crucial ?”\n`Anecdote` :\n\n&gt; « Mon petit-fils est allé à l'école et a appris à utiliser un ordinateur. Mais quand je lui ai demandé de me montrer comment discuter avec ces machines, il m'a dit que tout était en français ou en anglais. Alors j’ai ri et répondu : *Donc l'ordinateur ne parle pas ma langue ?* »\n\nCe projet est une réponse à cette réalité. Nous voulons donner une voix numérique aux langues tchadiennes et permettre à tous d’interagir avec la technologie sans barrière linguistique.\n\nNos objectifs\n\n1. Développer des chatbots en langues tchadiennes\nNotre premier défi est de créer des modèles NLP (Natural Language Processing) capables d’interagir en langues locales. Les Tchadiens pourront discuter avec une IA dans leur langue maternelle, pour obtenir des réponses à leurs questions, apprendre de nouvelles choses ou encore accéder à des services numériques.\nExemple d’interaction envisagée en arabe tchadien :\n\nUtilisateur : شيلكا في السوق اليوم؟ (Qu’y a-t-il au marché aujourd’hui ?)\nChatbot : اليوم فلفل، تمر، وسكر رخيص (Aujourd’hui, le piment, les dattes et le sucre sont à bon prix.)\n\nNous travaillerons d’abord sur l’arabe tchadien, puis nous étendrons aux langues comme le Ngambaye, Kanembou, Zaghawa, Moundang, Dadjo, le sara et bien d’autres.\n\n\n2. Construire des modèles de traduction\nUne fois les chatbots en place, nous voulons aller plus loin : développer des modèles de traduction automatique entre les langues tchadiennes, le français et l’anglais. Cela permettra par exemple de :\n\nTraduire des documents administratifs pour les rendre accessibles aux non-francophones.\nFaciliter l’enseignement et la diffusion de contenus éducatifs en langues locales.\nAider les Tchadiens à mieux communiquer avec le monde extérieur.\n\n\n\n3. Modèles vocaux (TTS et ASR)\nAujourd’hui, nous manquons de données audio pour les langues tchadiennes. Mais nous avons une vision : donner une voix aux langues locales grâce à des modèles de synthèse vocale (TTS - Text-To-Speech) et de reconnaissance vocale (ASR - Automatic Speech Recognition).\nPourquoi est-ce important ?\n\nUn agriculteur pourrait poser une question oralement à un assistant IA et obtenir une réponse vocale sur les meilleures pratiques agricoles d’autant plus que notre pays fait face à d’énormes défits agricoles.\nUn étudiant pourrait écouter des leçons dans sa langue maternelle au lieu de les lire.\nUne personne illettrée pourrait utiliser la technologie plus facilement.\n\nNous voulons enregistrer et annoter des heures de conversations, d’histoires traditionnelles et de discours pour construire ces modèles.\n\n\n\n\n\n\nAnecdote\n\n\n\nUn jour, nous avons demandé à une grand-mère tchadienne ce qu’elle aimerait voir dans une IA.\n\nElle nous a répondu : Un ordinateur qui me parle comme mes enfants !\n\nCe simple souhait résume tout l’enjeu de ce projet : rendre la technologie accessible et humaine, en respectant nos langues et nos cultures.\n\n\nNous ne devons pas rester passifs et éternels consommateurs.Pour cela nous aimerions rendre les outils d’IA universels et inclusifs, d’où la vitalité pour nous d’inclure nos voix et nos cultures dans cette technologie."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "license",
    "section": "",
    "text": "Droits d’auteur (c) 2025 CHad AI Network\nPar la présente, une permission est accordée, gratuitement, à toute personne obtenant une copie de ce logiciel et des fichiers de documentation associés (le “Logiciel”), de commercialiser le Logiciel sans restriction, y compris sans limitation les droits d’utiliser, de copier, de modifier, de fusionner, de publier, de distribuer, de sous-licencier et/ou de vendre des copies du Logiciel, et de permettre aux personnes auxquelles le Logiciel est fourni de le faire, sous réserve des conditions suivantes:\nLes avis de droits d’auteur ci-dessus et cet avis de permission doivent être inclus dans toutes les copies ou portions substantielles du Logiciel.\nLE LOGICIEL EST FOURNI “EN L’ÉTAT”, SANS GARANTIE D’AUCUNE SORTE, EXPLICITE OU IMPLICITE, Y COMPRIS MAIS SANS S’Y LIMITER AUX GARANTIES DE QUALITÉ MARCHANDE, D’ADÉQUATION À UN USAGE PARTICULIER ET D’ABSENCE DE CONTREFAÇON. EN AUCUN CAS, LES AUTEURS OU LES TITULAIRES DU DROIT D’AUTEUR NE SERONT RESPONSABLES DE TOUTE RÉCLAMATION, DOMMAGES OU AUTRE RESPONSABILITÉ, QU’IL S’AGISSE D’UNE ACTION CONTRACTUELLE, DÉLICTUELLE OU AUTRE, DÉCOULANT DE, DEHORS OU EN RELATION AVEC LE LOGICIEL OU L’UTILISATION OU D’AUTRES AFFAIRES DANS LE LOGICIEL.\n\n\nNous accueillons les contributions de la communauté. En contribuant à ce projet, vous acceptez de respecter les directives suivantes :\n\nCode de conduite : Veuillez lire et respecter notre Code de Conduite.\nPull Requests : Soumettez des pull requests pour les modifications. Assurez-vous que votre code passe tous les tests et respecte les normes de codage du projet.\nIssues : Signalez les problèmes en utilisant le traqueur de problèmes GitHub. Fournissez des informations détaillées pour nous aider à comprendre et à résoudre le problème.\nDocumentation : Mettez à jour la documentation si nécessaire pour refléter les modifications apportées à la base de code.\n\n\n\n\nEn utilisant ce logiciel, vous acceptez les termes suivants :\n\nAttribution : Si vous utilisez ce logiciel dans un projet, veuillez donner crédit à “CHad AI Network”.\nModifications : Si vous modifiez le logiciel, indiquez les modifications apportées et ne déformez pas l’origine du logiciel.\nConformité : Assurez-vous que votre utilisation du logiciel est conforme à toutes les lois et réglementations applicables.\n\nSi vous avez des questions ou avez besoin d’aide supplémentaire, veuillez nous contacter à email Chad AI Network."
  },
  {
    "objectID": "license.html#directives-de-contribution",
    "href": "license.html#directives-de-contribution",
    "title": "license",
    "section": "",
    "text": "Nous accueillons les contributions de la communauté. En contribuant à ce projet, vous acceptez de respecter les directives suivantes :\n\nCode de conduite : Veuillez lire et respecter notre Code de Conduite.\nPull Requests : Soumettez des pull requests pour les modifications. Assurez-vous que votre code passe tous les tests et respecte les normes de codage du projet.\nIssues : Signalez les problèmes en utilisant le traqueur de problèmes GitHub. Fournissez des informations détaillées pour nous aider à comprendre et à résoudre le problème.\nDocumentation : Mettez à jour la documentation si nécessaire pour refléter les modifications apportées à la base de code."
  },
  {
    "objectID": "license.html#utilisation-du-logiciel",
    "href": "license.html#utilisation-du-logiciel",
    "title": "license",
    "section": "",
    "text": "En utilisant ce logiciel, vous acceptez les termes suivants :\n\nAttribution : Si vous utilisez ce logiciel dans un projet, veuillez donner crédit à “CHad AI Network”.\nModifications : Si vous modifiez le logiciel, indiquez les modifications apportées et ne déformez pas l’origine du logiciel.\nConformité : Assurez-vous que votre utilisation du logiciel est conforme à toutes les lois et réglementations applicables.\n\nSi vous avez des questions ou avez besoin d’aide supplémentaire, veuillez nous contacter à email Chad AI Network."
  },
  {
    "objectID": "posts/data_collecte.html",
    "href": "posts/data_collecte.html",
    "title": "Collecte des données sur les langues tchadiennes",
    "section": "",
    "text": "Collecte et traitement des données pour SHU avec R et Python\nDans un projet NLP, la phase la plus complexe est la collecte et le traitement des données. Pour ce projet, c’est un défi majeur (qui m’a pris 4 mois), notamment en raison du manque de ressources structurées et de la diversité des formats de données. Dans cet article, nous allons aborder les différentes étapes et défis liés à l’extraction, la transformation et la structuration des données linguistiques obtenues à partir de sources variées (textes religieux, vocabulaires, grammaires) en utilisant R et Python.\n\nJ’espère qu’il vous sera utile. Il y a beaucoup de choses à discuter ici du côté pratique de cette collecte, mais j’essaierai d’être plus précis en vous fournissant que les informations nécessaires.\n\nLes points abordés dans cet article :\n\nScraping avec le package rvest de R: Extraction de textes de la Bible en arabe tchadien (shu)\nExtraction de textes depuis des PDF: Pourquoi l’OCR pose problème sur certains documents anciens et mal structurés\nNettoyage et prétraitement des données: Techniques pour normaliser et améliorer la qualité des textes extraits\nStructuration et tokenization des données: Transformation des données pour une meilleure exploitation en NLP\nExport et intégration des données: Formats adaptés pour entraîner des modèles NLP\n\n\n\n1. Scraping avec R et rvest\nUne grande partie des textes disponibles en langues tchadiennes sont dispersés sur des sites non structurés. Le package rvest permet d’extraire ces textes efficacement.\n```eny title=“scraping_shu.r” linenums=“1” library(rvest)\nurl &lt;- “https://bible.com/arabe-tchadien” page &lt;- read_html(url)\ntextes &lt;- page %&gt;% html_nodes(“p”) %&gt;% html_text()\nwriteLines(textes, “bible_arabe_tchadien.txt”)\n\n#### Défis rencontrés :\n\n- Certains sites affichent du texte en JavaScript, ce qui rend l’extraction plus complexe.\n- Les chapitres et versets sont parfois imbriqués dans des balises non standardisées.\n\n**Solutions possibles :**\n\n- Utilisation de Selenium pour exécuter le JavaScript avant d’extraire les données.\n- Extraction et nettoyage des balises avec des expressions régulières.\n\n### 2. Extraction de textes depuis des PDF\n\nLes PDF contenant des documents en langues tchadiennes sont souvent **anciens et mal structurés**. Même les outils OCR comme `tesseract` rencontrent des difficultés.\n\n#### Problèmes observés :\n\n- Mauvaise segmentation des caractères (ex : \"b'Allah\" devient \"b Allah\").\n- Perte d’information due à des polices de caractères non standardisées.\n- Disposition des colonnes non uniforme, ce qui fausse l’extraction.\n\n```{python} title=\"ocr_extractionPDF.py\" linenums=\"1\"\nimport pytesseract\nfrom pdf2image import convert_from_path\n\npages = convert_from_path(\"document.pdf\")\n\nfor i, page in enumerate(pages):\n    text = pytesseract.image_to_string(page, lang='ara')\n    with open(f\"output_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(text)\n\nSolutions et améliorations :\n\nUtiliser pdfminer.six pour extraire directement le texte au lieu de l’OCR si la couche texte est présente.\nSegmenter les colonnes manuellement pour reconstruire des phrases cohérentes.\nConvertir les documents en format HTML avant de les traiter pour un alignement plus précis.\n\n\n\n\n3. Nettoyage et prétraitement des données\nUne fois les données extraites, elles nécessitent un prétraitement rigoureux avant d’être utilisées pour le NLP.\n\nÉtapes principales :\n\nNormalisation des caractères (suppression des accents, homogénéisation de l’écriture des mots).\nCorrection des erreurs OCR avec des dictionnaires de mots.\nSegmentation des phrases et tokenization.\n\n```dbpikizj title=“preprocessing.py” linenums=“1” import re\ndef cle title=“preprocessing.py” linenums=“1”an_text(text): text = text.lower() text = re.sub(r”[^a-zA-Z0-9\\s]“,”“, text) # Suppression des caractères spéciaux return text text_cleaned = clean_text(”Allâh est mis en forme étrangement !“) print(text_cleaned) # ‘allah est mis en forme etrangement’\n\nCode APE vrai labelisé par le moteur de règles – nace (732 modalités)\nPrétraitements standards :\n\n- Passage en minuscules\n- Suppression de la ponctuation, des nombres et des stop words et la racinisation (stemming)\n\n### 4. Structuration et tokenization des données\n\nPour rendre les données exploitables par un modèle NLP, nous devons structurer les textes et segmenter les mots de manière efficace.\n\n- Passage en minusculeske\n- Suppression de la ponctuation, des nombres et des stop words et la racinisation (stemming)\n\n```{r} title=\"nettoyage.r\" linenums=\"1\"\nCerertains mots en ltexte &lt;- \"Allah est grand et miséricordieux\"\ntokens &lt;- tokenize_words(texte)\nprint(tokens)\nDéfi :od- Certains mots en langues tchadiennes sont concaténés et difficiles à segmenter sans un lexique adapté.\n\nCertaines langues utilisent des déclinaisons riches, rendant la tokenization plus complexe.\n\nSolutions possibles :\n\nDévelopper un tokenizer spécifique en utilisant un modèle statistique basé sur les fréquences des mots.\nEntraîner un modèle de segmentation de mots en deep learning pour affiner la tokenization."
  },
  {
    "objectID": "langues_tchadiennes.html",
    "href": "langues_tchadiennes.html",
    "title": "Projet NLP des langues tchadiennes",
    "section": "",
    "text": "Vous allez apprendre à faire le NLP sur les langues du Tchad"
  }
]